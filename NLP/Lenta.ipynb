{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=MorphAnalyzer()):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/lenta-ru-train.csv\")[:1000]\n",
    "test_data = pd.read_csv(\"data/lenta-ru-test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract lemmas from clean texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 81.37it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1667.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_label</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>title_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>Древних людей обвинили в вымирании гигантских ...</td>\n",
       "      <td>Ларс Верделин (Lars Werdelin) из Шведского муз...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>2</td>\n",
       "      <td>ларс верделина lars werdelin шведский музей ес...</td>\n",
       "      <td>древние человек обвинить вымирание гигантский ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Малкин избежал дисквалификации за драку на льду</td>\n",
       "      <td>Российский нападающий клуба НХЛ \"Питтсбург Пин...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>1</td>\n",
       "      <td>российский нападать клуб питтсбург пингвинс ев...</td>\n",
       "      <td>малкин избежать дисквалификация драка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>В Норвегии сыгран рекордный по продолжительнос...</td>\n",
       "      <td>Норвежские клубы «Сторхамар» и «Спарта» в матч...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>1</td>\n",
       "      <td>норвежский клуб сторхамар спарта матч плей выс...</td>\n",
       "      <td>норвегия сыгранный рекордный продолжительность...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Наставник футбольной сборной Испании оштрафова...</td>\n",
       "      <td>Главный тренер сборной Испании по футболу Луис...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>1</td>\n",
       "      <td>главный тренер сборный испания футбол луис ара...</td>\n",
       "      <td>наставник футбольный сборный испания оштрафова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Возмущения Солнца превратили в песню</td>\n",
       "      <td>Астрономы записали \"песню Солнца\" - им удалось...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>2</td>\n",
       "      <td>астроном записать песня солнце удаться преобра...</td>\n",
       "      <td>возмущение солнце превратить песня</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "828  Древних людей обвинили в вымирании гигантских ...   \n",
       "393    Малкин избежал дисквалификации за драку на льду   \n",
       "339  В Норвегии сыгран рекордный по продолжительнос...   \n",
       "564  Наставник футбольной сборной Испании оштрафова...   \n",
       "477               Возмущения Солнца превратили в песню   \n",
       "\n",
       "                                                  text            topic  \\\n",
       "828  Ларс Верделин (Lars Werdelin) из Шведского муз...  Наука и техника   \n",
       "393  Российский нападающий клуба НХЛ \"Питтсбург Пин...            Спорт   \n",
       "339  Норвежские клубы «Сторхамар» и «Спарта» в матч...            Спорт   \n",
       "564  Главный тренер сборной Испании по футболу Луис...            Спорт   \n",
       "477  Астрономы записали \"песню Солнца\" - им удалось...  Наука и техника   \n",
       "\n",
       "     topic_label                                             lemmas  \\\n",
       "828            2  ларс верделина lars werdelin шведский музей ес...   \n",
       "393            1  российский нападать клуб питтсбург пингвинс ев...   \n",
       "339            1  норвежский клуб сторхамар спарта матч плей выс...   \n",
       "564            1  главный тренер сборный испания футбол луис ара...   \n",
       "477            2  астроном записать песня солнце удаться преобра...   \n",
       "\n",
       "                                          title_lemmas  \n",
       "828  древние человек обвинить вымирание гигантский ...  \n",
       "393              малкин избежать дисквалификация драка  \n",
       "339  норвегия сыгранный рекордный продолжительность...  \n",
       "564  наставник футбольный сборный испания оштрафова...  \n",
       "477                 возмущение солнце превратить песня  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Pool(4) as p:\n",
    "    lemmas = list(tqdm(p.imap(clean_text, train_data['text']), total=len(train_data)))\n",
    "    title_lemmas = list(tqdm(p.imap(clean_text, train_data['title']), total=len(train_data)))\n",
    "    \n",
    "train_data['lemmas'] = lemmas\n",
    "train_data['title_lemmas'] = title_lemmas\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51660/51660 [10:14<00:00, 84.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>\"Челси\" не сумел купить бразильского форварда ...</td>\n",
       "      <td>Бразильский футбольный клуб \"Сантос\" отклонил ...</td>\n",
       "      <td>бразильский футбольный клуб сантос отклонить п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16877</th>\n",
       "      <td>Новый сенсор моментально обнаруживает в крови ...</td>\n",
       "      <td>Группа американских ученых из Калифорнийского ...</td>\n",
       "      <td>группа американский учёный калифорнийский унив...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51095</th>\n",
       "      <td>Журналисты отправили героев новой Call of Duty...</td>\n",
       "      <td>Действие следующей Call of Duty будет происход...</td>\n",
       "      <td>действие следующий call duty происходить космо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>Россия снизила ввозные пошлины на шубы в два раза</td>\n",
       "      <td>Российское правительство снизило с 15 сентября...</td>\n",
       "      <td>российский правительство снизить сентябрь став...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27386</th>\n",
       "      <td>Gibson выбрал лучшие металлические песни</td>\n",
       "      <td>Производитель гитар Gibson составил список из ...</td>\n",
       "      <td>производитель гитара gibson составить список х...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "19994  \"Челси\" не сумел купить бразильского форварда ...   \n",
       "16877  Новый сенсор моментально обнаруживает в крови ...   \n",
       "51095  Журналисты отправили героев новой Call of Duty...   \n",
       "6611   Россия снизила ввозные пошлины на шубы в два раза   \n",
       "27386           Gibson выбрал лучшие металлические песни   \n",
       "\n",
       "                                                    text  \\\n",
       "19994  Бразильский футбольный клуб \"Сантос\" отклонил ...   \n",
       "16877  Группа американских ученых из Калифорнийского ...   \n",
       "51095  Действие следующей Call of Duty будет происход...   \n",
       "6611   Российское правительство снизило с 15 сентября...   \n",
       "27386  Производитель гитар Gibson составил список из ...   \n",
       "\n",
       "                                                  lemmas  \n",
       "19994  бразильский футбольный клуб сантос отклонить п...  \n",
       "16877  группа американский учёный калифорнийский унив...  \n",
       "51095  действие следующий call duty происходить космо...  \n",
       "6611   российский правительство снизить сентябрь став...  \n",
       "27386  производитель гитара gibson составить список х...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Pool(4) as p:\n",
    "    lemmas = list(tqdm(p.imap(clean_text, test_data['text']), total=len(test_data)))\n",
    "    \n",
    "test_data['lemmas'] = lemmas\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data.lemmas, train_data.topic_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data[[\"lemmas\", \"title_lemmas\"]], train_data.topic_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = CountVectorizer(ngram_range=(1, 1))\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train[\"lemmas\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vec.transform(x_test[\"lemmas\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised('data.train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(train_data.lemmas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "clf.fit(bow, train_data.topic_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vec.transform(test_data.lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "res_df[\"id\"] = test_data.index\n",
    "res_df['category'] = pred\n",
    "res_df[['id','category']].to_csv('dummy_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
