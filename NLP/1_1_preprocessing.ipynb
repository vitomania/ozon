{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJToNZny8wiJ"
   },
   "source": [
    "<h1><center>Предобработка текста</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pipeline.png\" alt=\"pipeline.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrMWEuaj8wiM"
   },
   "source": [
    "### NLP-библиотеки\n",
    "\n",
    "NLP-библиотеки для питона:\n",
    "* Natural Language Toolkit (NLTK)\n",
    "* Stanford NLP suite\n",
    "* Spacy\n",
    "* Natasha, Yargy\n",
    "* DeepPavlov\n",
    "* и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJIhRR2V8wiN"
   },
   "source": [
    "## Предобработка текста\n",
    "\n",
    "1. **Токенизация** — Разбиение текста на токены (~ слова). \n",
    "2. Приведение к одному регистру, удаление пунктуации, исправление опечаток и т.д.\n",
    "3. **Нормализация**:\n",
    "    * **Стемминг** —  выделение псевдоосновы слова.\n",
    "    * **Лемматизация** — приведение слов к словарной (\"начальной\") форме.\n",
    "4. **Удаление стоп-слов** — слов, которые не несут никакой смысловой нагрузки (предлоги, союзы и т.п.)\n",
    "\n",
    "**Важно!** Не всегда нужны все этапы, все зависит от задачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uZhZrWq8wiN"
   },
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8I2LG_Bn8wiO"
   },
   "source": [
    "### Токен ≠ слово\n",
    "\n",
    "__Рассмотрим пример:__ \n",
    "\n",
    "Озон основан в 1998 году Санкт-Петербургской компанией «Reksoft» и издательством «Terra Fantastica» как торговый сервис для продажи книг и видео (VHS) через Интернет. Созданию магазина предшествовал запуск в октябре 1997 года интерактивной библиографической базы данных «Ad Verbum», на которой были отработаны способы представления информации и структуры баз данных. В начале 1998 года к «Ad Verbum» была добавлена также функциональность оформления заказа пользователем.\n",
    "Решение о создании на паритетных началах полнопрофильного интернет-магазина было принято компаниями-учредителями в конце 1997 года.\n",
    "Название магазина «Озон» было выбрано как «лёгкое слово», символизирующее «газ жизни», «лёгкий газ».\n",
    "\n",
    "https://ru.wikipedia.org/wiki/Ozon.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tMvWqXi8wiO",
    "outputId": "84a46e84-3e81-419c-8795-3f375c457e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Озон', 'основан', 'в', '1998', 'году', 'Санкт-Петербургской', 'компанией', '«Reksoft»', 'и', 'издательством', '«Terra', 'Fantastica»', 'как', 'торговый', 'сервис', 'для', 'продажи', 'книг', 'и', 'видео', '(VHS)', 'через', 'Интернет.', 'Созданию', 'магазина', 'предшествовал', 'запуск', 'в', 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', '«Ad', 'Verbum»,', 'на', 'которой', 'были', 'отработаны', 'способы', 'представления', 'информации', 'и', 'структуры', 'баз', 'данных.', 'В', 'начале', '1998', 'года', 'к', '«Ad', 'Verbum»', 'была', 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем.', 'Решение', 'о', 'создании', 'на', 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', 'было', 'принято', 'компаниями-учредителями', 'в', 'конце', '1997', 'года.', 'Название', 'магазина', '«Озон»', 'было', 'выбрано', 'как', '«лёгкое', 'слово»,', 'символизирующее', '«газ', 'жизни»,', '«лёгкий', 'газ».']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# самая простая токенизация: разбиение по пробелам\n",
    "\n",
    "text = '''\n",
    "Озон основан в 1998 году Санкт-Петербургской компанией «Reksoft» и издательством «Terra Fantastica» как торговый сервис для продажи книг и видео (VHS) через Интернет. Созданию магазина предшествовал запуск в октябре 1997 года интерактивной библиографической базы данных «Ad Verbum», на которой были отработаны способы представления информации и структуры баз данных. В начале 1998 года к «Ad Verbum» была добавлена также функциональность оформления заказа пользователем.\n",
    "Решение о создании на паритетных началах полнопрофильного интернет-магазина было принято компаниями-учредителями в конце 1997 года.\n",
    "Название магазина «Озон» было выбрано как «лёгкое слово», символизирующее «газ жизни», «лёгкий газ».\n",
    "'''\n",
    "\n",
    "tokens = text.split()\n",
    "print(tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EkpDhS6h8wiZ"
   },
   "outputs": [],
   "source": [
    "# !pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ACxgq8B8wib",
    "outputId": "01b95e08-2569-4b9e-c889-e50417d0ea90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/veronika/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('snowball_data')\n",
    "nltk.download('perluniprops')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('nonbreaking_prefixes')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIEMbLSA8wig",
    "outputId": "ebda2ff4-bb1f-42ba-d598-2ebed1392440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Озон', 'основан', 'в', '1998', 'году', 'Санкт-Петербургской', 'компанией', '«', 'Reksoft', '»', 'и', 'издательством', '«', 'Terra', 'Fantastica', '»', 'как', 'торговый', 'сервис', 'для', 'продажи', 'книг', 'и', 'видео', '(', 'VHS', ')', 'через', 'Интернет', '.', 'Созданию', 'магазина', 'предшествовал', 'запуск', 'в', 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', '«', 'Ad', 'Verbum', '»', ',', 'на', 'которой', 'были', 'отработаны', 'способы', 'представления', 'информации', 'и', 'структуры', 'баз', 'данных', '.', 'В', 'начале', '1998', 'года', 'к', '«', 'Ad', 'Verbum', '»', 'была', 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем', '.', 'Решение', 'о', 'создании', 'на', 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', 'было', 'принято', 'компаниями-учредителями', 'в', 'конце', '1997', 'года', '.', 'Название', 'магазина', '«', 'Озон', '»', 'было', 'выбрано', 'как', '«', 'лёгкое', 'слово', '»', ',', 'символизирующее', '«', 'газ', 'жизни', '»', ',', '«', 'лёгкий', 'газ', '»', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, ToktokTokenizer\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxaK7tB_8wii",
    "outputId": "051f5b1d-09fd-4151-9920-d771b4b8d556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Озон', 'основан', 'в', '1998', 'году', 'Санкт-Петербургской', 'компанией', '«Reksoft', '»', 'и', 'издательством', '«Terra', 'Fantastica', '»', 'как', 'торговый', 'сервис', 'для', 'продажи', 'книг', 'и', 'видео', '(', 'VHS', ')', 'через', 'Интернет.', 'Созданию', 'магазина', 'предшествовал', 'запуск', 'в', 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', '«Ad', 'Verbum', '»', ',', 'на', 'которой', 'были', 'отработаны', 'способы', 'представления', 'информации', 'и', 'структуры', 'баз', 'данных.', 'В', 'начале', '1998', 'года', 'к', '«Ad', 'Verbum', '»', 'была', 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем.', 'Решение', 'о', 'создании', 'на', 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', 'было', 'принято', 'компаниями-учредителями', 'в', 'конце', '1997', 'года.', 'Название', 'магазина', '«Озон', '»', 'было', 'выбрано', 'как', '«лёгкое', 'слово', '»', ',', 'символизирующее', '«газ', 'жизни', '»', ',', '«лёгкий', 'газ', '»', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = ToktokTokenizer()\n",
    "tokens = tknzr.tokenize(text)\n",
    "print(tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ghlw0kpe8wil",
    "outputId": "f4fb81b4-bdce-4bf5-8716-973adf52e7a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@kostossi',\n",
       " ':',\n",
       " '@VechernijUrgant',\n",
       " 'за',\n",
       " 'здоровый',\n",
       " 'образ',\n",
       " 'жизни',\n",
       " '!',\n",
       " 'Только',\n",
       " 'каши',\n",
       " ',',\n",
       " 'льняная',\n",
       " 'подойдет',\n",
       " ':)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# специальный токенизатор для твитов\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "tweet = \"RT @kostossi: @VechernijUrgant за здоровый образ жизни ! Только каши , льняная подойдет :)\"\n",
    "tknzr.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5CcKw7s8win",
    "outputId": "d46e9ad2-2341-4135-ac0e-247f66bf22b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'muffins',\n",
       " 'cost',\n",
       " '$3.88',\n",
       " 'in',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Please',\n",
       " 'buy',\n",
       " 'me',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " 'Thanks']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# токенизатор на регулярных выражениях\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "s = \"Good muffins cost $3.88 in New York.  Please buy me two of them. \\n\\nThanks.\"\n",
    "tknzr = RegexpTokenizer('\\w+|\\$[\\d\\.]+')\n",
    "tknzr.tokenize(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5FKqaxu8wiq"
   },
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlYxv5xy8wir",
    "outputId": "072605cf-2e9a-48a7-dc0b-e7d259e568f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'NLTKWordTokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'SyllableTokenizer',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0qzdWqY8wi2"
   },
   "source": [
    "## Сегментация предложений\n",
    "\n",
    "Сегментацию предложений иногда называют **сплиттингом**. \n",
    "\n",
    "Основные признаки — знаки препинания. \"?\", \"!\" как правило однозначны, проблемы возникают с \".\"  Возможное решение: бинарный классификатор для сегментации предложений. Для каждого символа определить, является ли оно концом предложения или нет.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RX2VhQT78wi2",
    "outputId": "3da92d9d-6bec-4eb8-f4c8-19520d1932e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nОзон основан в 1998 году Санкт-Петербургской компанией «Reksoft» и издательством «Terra Fantastica» как торговый сервис для продажи книг и видео (VHS) через Интернет.',\n",
       " 'Созданию магазина предшествовал запуск в октябре 1997 года интерактивной библиографической базы данных «Ad Verbum», на которой были отработаны способы представления информации и структуры баз данных.',\n",
       " 'В начале 1998 года к «Ad Verbum» была добавлена также функциональность оформления заказа пользователем.',\n",
       " 'Решение о создании на паритетных началах полнопрофильного интернет-магазина было принято компаниями-учредителями в конце 1997 года.',\n",
       " 'Название магазина «Озон» было выбрано как «лёгкое слово», символизирующее «газ жизни», «лёгкий газ».']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "print(len(sents))\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixKIivkm8wi-"
   },
   "source": [
    "### Удаление пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6E8o9W_8wi_",
    "outputId": "554fa4f4-fb52-4ded-e1d4-c416ffe9c42a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Озон', 'основан', 'в', '1998', 'году', 'Санкт-Петербургской', 'компанией', '«Reksoft»', 'и', 'издательством', '«Terra', 'Fantastica»', 'как', 'торговый', 'сервис', 'для', 'продажи', 'книг', 'и', 'видео', '(VHS)', 'через', 'Интернет.', 'Созданию', 'магазина', 'предшествовал', 'запуск', 'в', 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', '«Ad', 'Verbum»,', 'на', 'которой', 'были', 'отработаны', 'способы', 'представления', 'информации', 'и', 'структуры', 'баз', 'данных.', 'В', 'начале', '1998', 'года', 'к', '«Ad', 'Verbum»', 'была', 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем.', 'Решение', 'о', 'создании', 'на', 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', 'было', 'принято', 'компаниями-учредителями', 'в', 'конце', '1997', 'года.', 'Название', 'магазина', '«Озон»', 'было', 'выбрано', 'как', '«лёгкое', 'слово»,', 'символизирующее', '«газ', 'жизни»,', '«лёгкий', 'газ».']\n",
      "\n",
      "['Озон', 'основан', 'в', '1998', 'году', 'Санкт-Петербургской', 'компанией', '', 'Reksoft', '', 'и', 'издательством', '', 'Terra', 'Fantastica', '', 'как', 'торговый', 'сервис', 'для', 'продажи', 'книг', 'и', 'видео', '', 'VHS', '', 'через', 'Интернет', '', 'Созданию', 'магазина', 'предшествовал', 'запуск', 'в', 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', '', 'Ad', 'Verbum', '', '', 'на', 'которой', 'были', 'отработаны', 'способы', 'представления', 'информации', 'и', 'структуры', 'баз', 'данных', '', 'В', 'начале', '1998', 'года', 'к', '', 'Ad', 'Verbum', '', 'была', 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем', '', 'Решение', 'о', 'создании', 'на', 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', 'было', 'принято', 'компаниями-учредителями', 'в', 'конце', '1997', 'года', '', 'Название', 'магазина', '', 'Озон', '', 'было', 'выбрано', 'как', '', 'лёгкое', 'слово', '', '', 'символизирующее', '', 'газ', 'жизни', '', '', '', 'лёгкий', 'газ', '', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Способ №1\n",
    "import re\n",
    "\n",
    "# набор пунктуационных символов зависит от задачи и текста\n",
    "punct = '!\"#$%&()*\\+,-\\./:;<=>?@\\[\\]^_`{|}~„“«»†*\\—/\\-‘’'\n",
    "clean_text = re.sub(punct, r'', text)\n",
    "print(clean_text.split())\n",
    "print()\n",
    "# Способ №2\n",
    "clean_words = [w.strip(punct) for w in word_tokenize(text)]\n",
    "print(clean_words)\n",
    "\n",
    "clean_words == clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSSeJddy8wjC"
   },
   "source": [
    "### Преобразование регистра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fyovObi8wjD",
    "outputId": "06b20a69-3a76-4985-9a1f-bc8a8e896999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['озон', 'основан', 'в', '1998', 'году', 'санкт-петербургской', 'компанией', 'reksoft', 'и', 'издательством', 'terra', 'fantastica', 'как', 'торговый', 'сервис', 'для', 'продажи', 'книг', 'и', 'видео', 'vhs', 'через', 'интернет', 'созданию', 'магазина', 'предшествовал', 'запуск', 'в', 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', 'ad', 'verbum', 'на', 'которой', 'были', 'отработаны', 'способы', 'представления', 'информации', 'и', 'структуры', 'баз', 'данных', 'в', 'начале', '1998', 'года', 'к', 'ad', 'verbum', 'была', 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем', 'решение', 'о', 'создании', 'на', 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', 'было', 'принято', 'компаниями-учредителями', 'в', 'конце', '1997', 'года', 'название', 'магазина', 'озон', 'было', 'выбрано', 'как', 'лёгкое', 'слово', 'символизирующее', 'газ', 'жизни', 'лёгкий', 'газ']\n"
     ]
    }
   ],
   "source": [
    "clean_words = [w.lower() for w in clean_words if w != '']\n",
    "print(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKNDrwDQ8wjH"
   },
   "source": [
    "### Стоп-слова\n",
    "\n",
    "**Стоп-слова** — высокочастотные слова, которые не дают нам никакой информации о конкретном тексте. Они составляют верхушку частотного списка в любом языке. Набор стоп-слов не универсален, он будет зависеть от вашей задачи!\n",
    "\n",
    "В NLTK есть готовые списки стоп-слов для многих языков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42F9WthB8wjI",
    "outputId": "cb73e3a8-dfe4-4e34-f487-9e8dd0c1c5fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# смотрим, какие языки есть\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-GBMG498wjK",
    "outputId": "f2ceb7f3-e74f-42c4-db6e-35f421cadf78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "sw = stopwords.words('russian')\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PY6slf1G8wjM",
    "outputId": "81a46505-35e3-44d2-b301-71a8b810cae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в\n",
      "и\n",
      "как\n",
      "для\n",
      "и\n",
      "через\n",
      "в\n",
      "на\n",
      "были\n",
      "и\n",
      "в\n",
      "к\n",
      "была\n",
      "о\n",
      "на\n",
      "было\n",
      "в\n",
      "было\n",
      "как\n",
      "['озон', 'основан', None, '1998', 'году', 'санкт-петербургской', 'компанией', 'reksoft', None, 'издательством', 'terra', 'fantastica', None, 'торговый', 'сервис', None, 'продажи', 'книг', None, 'видео', 'vhs', None, 'интернет', 'созданию', 'магазина', 'предшествовал', 'запуск', None, 'октябре', '1997', 'года', 'интерактивной', 'библиографической', 'базы', 'данных', 'ad', 'verbum', None, 'которой', None, 'отработаны', 'способы', 'представления', 'информации', None, 'структуры', 'баз', 'данных', None, 'начале', '1998', 'года', None, 'ad', 'verbum', None, 'добавлена', 'также', 'функциональность', 'оформления', 'заказа', 'пользователем', 'решение', None, 'создании', None, 'паритетных', 'началах', 'полнопрофильного', 'интернет-магазина', None, 'принято', 'компаниями-учредителями', None, 'конце', '1997', 'года', 'название', 'магазина', 'озон', None, 'выбрано', None, 'лёгкое', 'слово', 'символизирующее', 'газ', 'жизни', 'лёгкий', 'газ']\n"
     ]
    }
   ],
   "source": [
    "print([w if w not in sw else print(w) for w in clean_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JiMMLtZp8wjN"
   },
   "source": [
    "## Стемминг\n",
    "\n",
    "**Стемминг** — отсечение от слова окончаний и суффиксов, чтобы оставшаяся часть, называемая stem, была одинаковой для всех грамматических форм слова. Стем необязательно совпадает с морфлогической основой слова. Одинаковый стем может получиться и не у однокоренных слов и наоборот — в этом проблема стемминга. \n",
    "\n",
    "* 1-ый вид ошибки: белый, белка, белье $\\implies$  бел\n",
    "\n",
    "* 2-ой вид ошибки: трудность, трудный $\\implies$  трудност, труд \n",
    "\n",
    "* 3-ий вид ошибки: быстрый, быстрее $\\implies$  быст, побыстрее $\\implies$  побыст\n",
    "\n",
    "Самый простой алгоритм, алгоритм Портера, состоит из 5 циклов команд, на каждом цикле – операция удаления / замены суффикса. Возможны вероятностные расширения алгоритма.\n",
    "\n",
    "### Snowball stemmer\n",
    "Улучшенный вариант стеммера Портера; в отличие от него умеет работать не только с английским текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7ni6c5T8wjO",
    "outputId": "77fd8762-e949-4d29-857c-70acd4e785bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "SnowballStemmer.languages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbnbMdNm8wjQ"
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "OZON – крупнейший интернет-магазин, где есть абсолютно всё: электроника, одежда, косметика, книги, зоотовары, продукты и многое другое.\n",
    "'''\n",
    "\n",
    "words = [w.strip(punct).lower() for w in word_tokenize(text)]\n",
    "words = [w for w in words if w not in sw and w != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrtC521I8wjW",
    "outputId": "d83af65c-48b5-4c9a-d1c2-8335b9d0ffbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozon: ozon\n",
      "–: –\n",
      "крупнейший: крупн\n",
      "интернет-магазин: интернет-магазин\n",
      "абсолютно: абсолютн\n",
      "всё: все\n",
      "электроника: электроник\n",
      "одежда: одежд\n",
      "косметика: косметик\n",
      "книги: книг\n",
      "зоотовары: зоотовар\n",
      "продукты: продукт\n",
      "многое: мног\n",
      "другое: друг\n"
     ]
    }
   ],
   "source": [
    "snowball = SnowballStemmer(\"russian\")\n",
    "\n",
    "for w in words:\n",
    "    print(\"%s: %s\" % (w, snowball.stem(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eREMBHVY8wjY"
   },
   "source": [
    "## Морфологический анализ\n",
    "\n",
    "Задачи морфологического анализа:\n",
    "\n",
    "* Разбор слова — определение нормальной формы (леммы), основы (стема) и грамматических характеристик слова\n",
    "* Синтез словоформы — генерация словоформы по заданным грамматическим характеристикам из леммы\n",
    "\n",
    "Морфологический анализ — не самая сильная сторона NLTK.  Для этих задач лучше использовать `pymorphy2` и `pymystem3` для русского языка и, например, `Spacy` для европейских.\n",
    "\n",
    "## Лемматизация\n",
    "\n",
    "**Лемматизация** — процесс приведения словоформы к лемме, т.е. нормальной (словарной) форме. Это более сложная задача, чем стемминг, но и результаты дает гораздо более осмысленные, особенно для языков с богатой морфологией.\n",
    "\n",
    "* кошке, кошку, кошкам, кошкой $\\implies$ кошка\n",
    "* бежал, бежит, бегу $\\implies$  бежать\n",
    "* белому, белым, белыми $\\implies$ белый\n",
    "\n",
    "## POS-tagging\n",
    "\n",
    "**Частеречная разметка**, или **POS-tagging** _(part of speech tagging)_ —  определение части речи и грамматических характеристик слов в тексте (корпусе) с приписыванием им соответствующих тегов.\n",
    "\n",
    "Для большинства слов возможно несколько разборов (т.е. несколько разных лемм, несколько разных частей речи и т.п.). Теггер генерирует  все варианты, ранжирует их по вероятности и по умолчанию выдает наиболее вероятный. Выбор одного разбора из нескольких называется **снятием омонимии**, или **дизамбигуацией**.\n",
    "\n",
    "### Наборы тегов\n",
    "\n",
    "Существует множество наборов грамматических тегов, или тегсетов:\n",
    "* НКРЯ\n",
    "* Mystem\n",
    "* UPenn\n",
    "* OpenCorpora (его использует pymorphy2)\n",
    "* Universal Dependencies\n",
    "* ...\n",
    "\n",
    "Есть даже [библиотека](https://github.com/kmike/russian-tagsets) для преобразования тегов из одной системы в другую для русского языка, `russian-tagsets`. Но важно помнить, что любое такое преобразование будет с потерями! \n",
    "\n",
    "На данный момент стандартом является **Universal Dependencies**. Подробнее про проект можно почитать [вот тут](http://universaldependencies.org/), а про теги — [вот тут](http://universaldependencies.org/u/pos/)\n",
    "\n",
    "### pymystem3\n",
    "\n",
    "**pymystem3** — это питоновская обертка для морфологичекого анализатора Mystem, сделанного в Яндексе. Его можно скачать отдельно и использовать из консоли. Отдельный плюс Mystem - он умеет разрешать омонимию (выбирает более релевантный вариант разбора слова для данного контекста).\n",
    "\n",
    "Инициализируем Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IClsgWM58wjY"
   },
   "outputs": [],
   "source": [
    "# ! pip install --user pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jm48dgcB8wja",
    "outputId": "2c56f6d6-b8a4-46ec-a7c3-e202728ff39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ozon', ' – ', 'крупный', ' ', 'интернет', '-', 'магазин', ' ', 'абсолютно', ' ', 'все', ' ', 'электроника', ' ', 'одежда', ' ', 'косметика', ' ', 'книга', ' ', 'зоотовары', ' ', 'продукт', ' ', 'многий', ' ', 'другой', '\\n']\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "lemmas = m.lemmatize(' '.join(words))\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04rPVaGg8wjd",
    "outputId": "5122f269-d85f-45b8-bcd3-b3b69b081ba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis': [{'lex': 'крупный',\n",
       "   'wt': 1,\n",
       "   'gr': 'A=(вин,ед,полн,прев,муж,неод|им,ед,полн,прев,муж)'}],\n",
       " 'text': 'крупнейший'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = m.analyze(text)\n",
    "parsed[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMf3iMoe8wjf",
    "outputId": "67a71938-9b6a-4888-c167-32cb2c1a52a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "крупнейший A\n",
      "интернет S\n",
      "магазин S\n",
      "где ADVPRO\n",
      "есть V\n",
      "абсолютно ADV\n",
      "всё ADV\n",
      "электроника S\n",
      "одежда S\n",
      "косметика S\n",
      "книги S\n",
      "зоотовары S\n",
      "продукты S\n",
      "и CONJ\n",
      "многое APRO\n",
      "другое APRO\n"
     ]
    }
   ],
   "source": [
    "# как достать части речи\n",
    "\n",
    "for word in parsed:\n",
    "    if 'analysis' in word:\n",
    "        gr = word.get('analysis')\n",
    "        if len(gr):\n",
    "            pos = gr[0]['gr'].split('=')[0].split(',')[0]\n",
    "            print(word['text'], pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTJsMuTX8wjh"
   },
   "source": [
    "###  pymorphy2\n",
    "\n",
    "**pymorphy2** — это полноценный морфологический анализатор, целиком написанный на Python. В отличие от Mystem, он не учитывает контекст, а значит, вопрос разрешения омонимии надо будет решать нам самим (об этом ниже). Он также умеет ставить слова в нужную форму (спрягать и склонять). \n",
    "\n",
    "[Документация pymorphy2](https://pymorphy2.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fGOCBpL8wji"
   },
   "outputs": [],
   "source": [
    "# ! pip install --user pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxFHvLVx8wjm",
    "outputId": "4ff64967-8700-4690-b8e2-ebe62d12a418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='стали', tag=OpencorporaTag('VERB,perf,intr plur,past,indc'), normal_form='стать', score=0.984662, methods_stack=((<DictionaryAnalyzer>, 'стали', 904, 4),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 1),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 2),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 5),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 6),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='сталь', score=0.003067, methods_stack=((<DictionaryAnalyzer>, 'стали', 13, 9),))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "p = morph.parse('стали')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGfkuMnT8wjo",
    "outputId": "f8b55225-f9d7-48bf-e62b-87ea03b3dedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: стали\n",
      "Тэг: VERB,perf,intr plur,past,indc\n",
      "Лемма: стать\n",
      "Вероятность: 0.984662\n"
     ]
    }
   ],
   "source": [
    "first = p[0]  # первый разбор\n",
    "print('Слово:', first.word)\n",
    "print('Тэг:', first.tag)\n",
    "print('Лемма:', first.normal_form)\n",
    "print('Вероятность:', first.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_vXOl2G8wjq"
   },
   "source": [
    "Из каждого тега можно достать более дробную информацию. Если граммема есть в разборе, то вернется ее значение, если ее нет, то вернется None. [Список граммем](https://pymorphy2.readthedocs.io/en/latest/user/grammemes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfN8Jlav8wjq",
    "outputId": "25c17742-4cf6-4f94-c7a7-ad0547677d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='стать', tag=OpencorporaTag('INFN,perf,intr'), normal_form='стать', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'стать', 904, 0),))\n",
      "VERB\n",
      "None\n",
      "perf\n",
      "None\n",
      "None\n",
      "None\n",
      "indc\n",
      "plur\n",
      "None\n",
      "past\n",
      "intr\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(first.normalized)        # лемма\n",
    "print(first.tag.POS)           # Part of Speech, часть речи\n",
    "print(first.tag.animacy)       # одушевленность\n",
    "print(first.tag.aspect)        # вид: совершенный или несовершенный\n",
    "print(first.tag.case)          # падеж\n",
    "print(first.tag.gender)        # род (мужской, женский, средний)\n",
    "print(first.tag.involvement)   # включенность говорящего в действие\n",
    "print(first.tag.mood)          # наклонение (повелительное, изъявительное)\n",
    "print(first.tag.number)        # число (единственное, множественное)\n",
    "print(first.tag.person)        # лицо (1, 2, 3)\n",
    "print(first.tag.tense)         # время (настоящее, прошедшее, будущее)\n",
    "print(first.tag.transitivity)  # переходность (переходный, непереходный)\n",
    "print(first.tag.voice)         # залог (действительный, страдательный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZtVGFG08wjt",
    "outputId": "c28492a8-f725-42c1-bfa3-f69c361600b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='стать', tag=OpencorporaTag('INFN,perf,intr'), normal_form='стать', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'стать', 904, 0),))\n",
      "VERB\n",
      "perf\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(first.normalized)      \n",
    "print(first.tag.POS)\n",
    "print(first.tag.aspect)\n",
    "print(first.tag.case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZA9awaI8wjy"
   },
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) Оба они могут работать с незнакомыми словами (out-of-vocabulary words, OOV).\n",
    "\n",
    "2) *Скорость*. Mystem работает невероятно медленно под windows на больших текстах, но очень быстро, елси запускать из консоли в linux / mac os.\n",
    "\n",
    "3) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ot_d8SfS8wjz",
    "outputId": "193e14ea-4c62-4554-9a8b-dfc6633e0348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-jgHkHi8wj2"
   },
   "outputs": [],
   "source": [
    "p = morph.parse('сорока')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qp_VxYoJ8wj4",
    "outputId": "08219ec5-3143-4862-e6cd-eb979d9a4223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='сорока', tag=OpencorporaTag('NUMR loct'), normal_form='сорок', score=0.285714, methods_stack=((<DictionaryAnalyzer>, 'сорока', 2802, 5),)),\n",
       " Parse(word='сорока', tag=OpencorporaTag('NOUN,inan,femn sing,nomn'), normal_form='сорока', score=0.142857, methods_stack=((<DictionaryAnalyzer>, 'сорока', 43, 0),)),\n",
       " Parse(word='сорока', tag=OpencorporaTag('NOUN,anim,femn sing,nomn'), normal_form='сорока', score=0.142857, methods_stack=((<DictionaryAnalyzer>, 'сорока', 403, 0),)),\n",
       " Parse(word='сорока', tag=OpencorporaTag('NUMR gent'), normal_form='сорок', score=0.142857, methods_stack=((<DictionaryAnalyzer>, 'сорока', 2802, 1),)),\n",
       " Parse(word='сорока', tag=OpencorporaTag('NUMR datv'), normal_form='сорок', score=0.142857, methods_stack=((<DictionaryAnalyzer>, 'сорока', 2802, 2),)),\n",
       " Parse(word='сорока', tag=OpencorporaTag('NUMR ablt'), normal_form='сорок', score=0.142857, methods_stack=((<DictionaryAnalyzer>, 'сорока', 2802, 4),))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Собираем все вместе:\n",
    "\n",
    "Сделаем стандартную предобработку данных с сайта Lenta.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_preprocessing.ipynb      lenta-ru-test.csv\r\n",
      "1_1_regex.ipynb              pipeline.png\r\n",
      "1_3_simple_text_models.ipynb pipeline_vec.png\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                         re_memes.jpg\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48568</th>\n",
       "      <td>Люди, не состоящие в зарегистрированном браке, имеют более насыщенную социальную жизнь и больший психологический рост, чем их сверстники, состоящие в браке. Об этом ученые рассказали на ежегодной 124-й конференции Американской психологической ассоциации, сообщает издание EurekAlert! Специалисты провели метаанализ более 800 работ, сконцентрированных на исследовании одиноких людей. Большинство из них сравнивает таких людей с теми, кто состоит в зарегистрированном браке. Проведенное учеными исследование, охватывающее длительный период времени, показало, что одинокие люди имеют обостренное чувство самоопределения и склонны испытывать «чувство непрерывного роста и развития как человека». Оказалось, что одинокие люди часто ценят свою работу больше, чем семейные. Согласно другому исследованию...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48656</th>\n",
       "      <td>Две мексиканские компании начали импортировать российский шоколад. Первый контейнер пришел в феврале и сейчас лакомство уже можно приобрести в мексиканских магазинах, сообщает РИА Новости. «Мы уже начали поставки, но пока мы только в начале пути, в сфере продаж мы сейчас идем в крупные торговые сети Мексики, также работаем с бутиками шоколада, магазинами деликатесов в столице и уже начинаем выходить на территорию штата Мехико», — цитирует агентство директора компании Edelweiss Хуан Леон, которая импортирует российский шоколад. Шоколад появился на территории нынешней Мексики во времена индейцев майя и ацтеков. Позже он благодаря конкистадорам завоевал Европу, а теперь возвращается на свою историческую родину, но уже в российской презентации. По данным Российского экспортного центра, оте...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34055</th>\n",
       "      <td>Полузащитник английского футбольного клуба \"Манчестер Юнайтед\" Райан Гиггз пропустит матч чемпионата страны с лондонским \"Арсеналом\". Главный тренер \"МЮ\" сэр Алекс Фергюсон даст 37-летнему футболисту отдых после полуфинальной игры Лиги чемпионов с немецким \"Шальке\" (2:0), в которой Гиггз забил один из голов. Об этом сообщает официальный сайт манчестерской команды. Фергюсон предположил, что Гиггз сможет сыграть в ответном матче с \"Шальке\", который состоится 4 мая. Тренер отметил, что сам игрок, несмотря на возраст, не чувствует усталости от игр. Матч \"Арсенал\" - \"Манчестер Юнайтед\" состоится 1 мая. За четыре тура до конца первенства страны \"МЮ\", лидирующий в премьер-лиге, опережает лондонский \"Челси\" на шесть очков, а \"Арсенал\" - на девять очков.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46922</th>\n",
       "      <td>В Сети появилась презентация от августа 2010 года, в которой описаны планы Microsoft на консоль следующего поколения, сообщает VG24/7. Документ был размещен на сайте Scribd.com. Вскоре после того, как информация об этом попала в СМИ, презентация была удалена с этого сайта по требованию юридической компании Covington &amp; Burling, которая сотрудничает с Microsoft. Согласно презентации, релиз консоли Xbox следующего поколения (так называемой Xbox 720) состоится в 2013 году (в начале или в конце года - неясно). Тогда же выйдет новая версия контроллера Kinect - Kinect 2.0. Стоимость приставки составит 299 долларов. Сообщается, что уже после релиза Microsoft планирует выпустить стереоскопические очки, которые также будут поддерживать технологию \"дополненной реальности\". В презентации также уто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>Министерство культуры РФ получило полторы тысячи заявок на кинопроекты, претендующие на бюджетные субсидии, пишет \"Независимая газета\". По словам статс-секретаря - замминистра культуры Екатерины Чуковской, прием заявок завершился 1 августа. В ближайшее время эксперты займутся изучением проектов. Предполагается, что этот процесс завершится к середине сентября, после чего будет составлен рейтинг, на основе которого и произойдет распределение средств. Чуковская также рассказала, что Министерству культуры предстоит распределить ресурсы между фильмами пяти категорий. Речь идет о дебютных лентах, документальном кино, анимации, игровых фильмах для детей и авторских работах. Описание категории \"авторское кино\", по мнению Чуковской, \"довольно расплывчато\" и не имеет \"четкой границы\". В марте 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text\n",
       "48568  Люди, не состоящие в зарегистрированном браке, имеют более насыщенную социальную жизнь и больший психологический рост, чем их сверстники, состоящие в браке. Об этом ученые рассказали на ежегодной 124-й конференции Американской психологической ассоциации, сообщает издание EurekAlert! Специалисты провели метаанализ более 800 работ, сконцентрированных на исследовании одиноких людей. Большинство из них сравнивает таких людей с теми, кто состоит в зарегистрированном браке. Проведенное учеными исследование, охватывающее длительный период времени, показало, что одинокие люди имеют обостренное чувство самоопределения и склонны испытывать «чувство непрерывного роста и развития как человека». Оказалось, что одинокие люди часто ценят свою работу больше, чем семейные. Согласно другому исследованию...\n",
       "48656  Две мексиканские компании начали импортировать российский шоколад. Первый контейнер пришел в феврале и сейчас лакомство уже можно приобрести в мексиканских магазинах, сообщает РИА Новости. «Мы уже начали поставки, но пока мы только в начале пути, в сфере продаж мы сейчас идем в крупные торговые сети Мексики, также работаем с бутиками шоколада, магазинами деликатесов в столице и уже начинаем выходить на территорию штата Мехико», — цитирует агентство директора компании Edelweiss Хуан Леон, которая импортирует российский шоколад. Шоколад появился на территории нынешней Мексики во времена индейцев майя и ацтеков. Позже он благодаря конкистадорам завоевал Европу, а теперь возвращается на свою историческую родину, но уже в российской презентации. По данным Российского экспортного центра, оте...\n",
       "34055                                              Полузащитник английского футбольного клуба \"Манчестер Юнайтед\" Райан Гиггз пропустит матч чемпионата страны с лондонским \"Арсеналом\". Главный тренер \"МЮ\" сэр Алекс Фергюсон даст 37-летнему футболисту отдых после полуфинальной игры Лиги чемпионов с немецким \"Шальке\" (2:0), в которой Гиггз забил один из голов. Об этом сообщает официальный сайт манчестерской команды. Фергюсон предположил, что Гиггз сможет сыграть в ответном матче с \"Шальке\", который состоится 4 мая. Тренер отметил, что сам игрок, несмотря на возраст, не чувствует усталости от игр. Матч \"Арсенал\" - \"Манчестер Юнайтед\" состоится 1 мая. За четыре тура до конца первенства страны \"МЮ\", лидирующий в премьер-лиге, опережает лондонский \"Челси\" на шесть очков, а \"Арсенал\" - на девять очков.\n",
       "46922  В Сети появилась презентация от августа 2010 года, в которой описаны планы Microsoft на консоль следующего поколения, сообщает VG24/7. Документ был размещен на сайте Scribd.com. Вскоре после того, как информация об этом попала в СМИ, презентация была удалена с этого сайта по требованию юридической компании Covington & Burling, которая сотрудничает с Microsoft. Согласно презентации, релиз консоли Xbox следующего поколения (так называемой Xbox 720) состоится в 2013 году (в начале или в конце года - неясно). Тогда же выйдет новая версия контроллера Kinect - Kinect 2.0. Стоимость приставки составит 299 долларов. Сообщается, что уже после релиза Microsoft планирует выпустить стереоскопические очки, которые также будут поддерживать технологию \"дополненной реальности\". В презентации также уто...\n",
       "1937   Министерство культуры РФ получило полторы тысячи заявок на кинопроекты, претендующие на бюджетные субсидии, пишет \"Независимая газета\". По словам статс-секретаря - замминистра культуры Екатерины Чуковской, прием заявок завершился 1 августа. В ближайшее время эксперты займутся изучением проектов. Предполагается, что этот процесс завершится к середине сентября, после чего будет составлен рейтинг, на основе которого и произойдет распределение средств. Чуковская также рассказала, что Министерству культуры предстоит распределить ресурсы между фильмами пяти категорий. Речь идет о дебютных лентах, документальном кино, анимации, игровых фильмах для детей и авторских работах. Описание категории \"авторское кино\", по мнению Чуковской, \"довольно расплывчато\" и не имеет \"четкой границы\". В марте 20..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "data = pd.read_csv('lenta-ru-test.csv', usecols=['text'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "\n",
    "# убираем все небуквенные символы\n",
    "regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В южноафриканском Кейптауне победой сборной России завершился чемпионат мира среди бездомных. В финальном матче российские футболисты, впервые в своей истории ставшие чемпионами мира, обыграли команду Казахстана со счетом 1:0, передает BBC News. В первенстве принимали участие почти 500 человек, которые представляли 48 стран мира. Все матчи, каждый из которых продолжался 15 минут, проходили на асфальтовых полях, причем в одной команде могли играть как мужчины, так и женщины. Сборная России провела на турнире 13 матчей, во всех из которых добилась победы. На предыдущих чемпионатах мира достижения российской команды были скромнее: в 2003-м году – 13-е место, в 2004-м году – 5-е место, в 2005-м году – 12-е место.\n"
     ]
    }
   ],
   "source": [
    "print(data.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в южноафриканском кейптауне победой сборной россии завершился чемпионат мира среди бездомных в финальном матче российские футболисты впервые в своей истории ставшие чемпионами мира обыграли команду казахстана со счетом передает bbc news в первенстве принимали участие почти человек которые представляли стран мира все матчи каждый из которых продолжался минут проходили на асфальтовых полях причем в одной команде могли играть как мужчины так и женщины сборная россии провела на турнире матчей во всех из которых добилась победы на предыдущих чемпионатах мира достижения российской команды были скромнее в м году е место в м году е место в м году е место\n"
     ]
    }
   ],
   "source": [
    "print(*words_only(data.text[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод @lru_cashe создает для функции lemmatize кэш указанного размера, что позволяет в целом ускорить лемматизацию текста (что очень полезно, так как лемматизация - ресурсоемкий процесс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['в', 'южноафриканский', 'кейптаун', 'победа', 'сборный', 'россия', 'завершиться', 'чемпионат', 'мир', 'среди', 'бездомный', 'в', 'финальный', 'матч', 'российский', 'футболист', 'впервые', 'в', 'свой', 'история', 'стать', 'чемпион', 'мир', 'обыграть', 'команда', 'казахстан', 'с', 'счёт', 'передавать', 'bbc', 'news', 'в', 'первенство', 'принимать', 'участие', 'почти', 'человек', 'который', 'представлять', 'страна', 'мир', 'весь', 'матч', 'каждый', 'из', 'который', 'продолжаться', 'минута', 'проходить', 'на', 'асфальтовый', 'поле', 'причём', 'в', 'один', 'команда', 'мочь', 'играть', 'как', 'мужчина', 'так', 'и', 'женщина', 'сборная', 'россия', 'провести', 'на', 'турнир', 'матч', 'в', 'весь', 'из', 'который', 'добиться', 'победа', 'на', 'предыдущий', 'чемпионат', 'мир', 'достижение', 'российский', 'команда', 'быть', 'скромный', 'в', 'метр', 'год', 'е', 'место', 'в', 'метр', 'год', 'е', 'место', 'в', 'метр', 'год', 'е', 'место']\n"
     ]
    }
   ],
   "source": [
    "tokens = words_only(data.text[0])\n",
    "\n",
    "print(lemmatize_text(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = stopwords.words('russian') \n",
    "\n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "южноафриканский кейптаун победа сборный россия завершиться чемпионат мир среди бездомный финальный матч российский футболист впервые свой история стать чемпион мир обыграть команда казахстан счёт передавать bbc news первенство принимать участие человек который представлять страна мир весь матч каждый который продолжаться минута проходить асфальтовый поле причём команда мочь играть мужчина женщина сборная россия провести турнир матч весь который добиться победа предыдущий чемпионат мир достижение российский команда скромный метр год е место метр год е место метр год е место\n"
     ]
    }
   ],
   "source": [
    "lemmas = lemmatize_text(tokens)\n",
    "\n",
    "print(*remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "южноафриканский кейптаун победа сборный россия завершиться чемпионат среди бездомный финальный матч российский футболист впервые свой история стать чемпион обыграть команда казахстан счёт передавать news первенство принимать участие человек который представлять страна весь матч каждый который продолжаться минута проходить асфальтовый поле причём команда мочь играть мужчина женщина сборная россия провести турнир матч весь который добиться победа предыдущий чемпионат достижение российский команда скромный метр место метр место метр место\n"
     ]
    }
   ],
   "source": [
    "print(*remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если собрать все в одну функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return remove_stopwords(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "известный голливудский актёр майкл дуглас совершить неожиданный визит сообщать издание cubadebate цель поездка дуглас уточняться утверждаться лишь актёр посетить несколько памятный место число закусочный floridita который некогда любить бывать эрнест хемингуэй майкл дуглас также осмотреть достопримечательность исторический центр гавана понаблюдать процесс изготовление кубинский сигара табачный фабрика стоить отметить свободный посещение куба американский гражданин иметь родственник остров запретить американец поездка требоваться специальный разрешение государственный департамент получать дуглас разрешение сообщаться напомнить дуглас единственный знаменитый голливудский актёр посетить последний время ранее страна качество корреспондент журнал vanity fair прибыть визит пенна двукратный обладатель премия оскар намереваться взять интервью фидель кастро поездка пенный сопровождать известный филантроп дайана дженкинс\n"
     ]
    }
   ],
   "source": [
    "print(*clean_text(data.text[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно предобработать большой объем текста, помимо кэширования может помочь распараллеливание, например, методом Pool библиотеки multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93c88776ab5478d854d266b275ef083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 200\n",
    "\n",
    "with Pool(8) as p:\n",
    "    lemmas = list(tqdm(p.imap(clean_text, data['text'][:N]), total=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Клуб НХЛ \"Вашингтон Кэпиталс\" проиграл второй матч серии 1/4 финала Кубка Стэнли. На своей площадке \"Вашингтон\" уступил команде \"Тампа-Бей Лайтнинг\" со счетом 2:3. Таким образом, \"Тампа\" повела в серии до четырех побед со счетом 2:0. Об этом сообщает официальный сайт лиги. В концовке первого периода счет открыл хоккеист \"Тампы\" Венсан Лекавалье. На 35-й минуте отличился игрок \"Вашингтона\" Брук Лайк. В середине третьего периода \"Тампа\" вновь вышла вперед - шайбу забросил Мартен Сен-Луи. За минуту и восемь секунд до конца основного времени Александр Овечкин перевел игру в овертайм, но в дополнительное время \"Тампа\" добилась победы - вновь отличился Лекавалье. В другом матче, состоявшемся в ночь с 1 на 2 мая, \"Сан-Хосе Шаркс\" обыграл \"Детройт Ред Уингс\" со счетом 2:1. \"Сан-Хосе\" ведет в с...</td>\n",
       "      <td>[клуб, вашингтон, кэпиталс, проиграть, матч, серия, финал, кубок, стэнли, свой, площадка, вашингтон, уступить, команда, тампа, бить, лайтнинга, счёт, образ, тампа, повести, серия, четыре, победа, счёт, сообщать, официальный, сайт, лига, концовка, первое, период, счёт, открыть, хоккеист, тамп, венсан, лекавалье, минута, отличиться, игрок, вашингтон, брук, лайк, середина, третье, период, тампа, вновь, выйти, вперёд, шайба, забросить, мартен, минута, восемь, секунда, конец, основный, время, александр, овечкин, перевести, игра, овертайм, дополнительный, время, тампа, добиться, победа, вновь, отличиться, лекавалье, друг, матч, состояться, ночь, хосе, шаркс, обыграть, детройт, уингс, счёт, хосе, вести, серия, счёт, серия, нэшвилл, предаторс, ванкувер, кэнакс, матч, счёт, равный, бостон, брюи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Предстоящий третий сезон телесериала «Служба новостей» («Newsroom»), выходящего на телеканале HBO, станет последним. Об этом, сообщает Reuters, в понедельник, 13 января, объявила пресс-служба телеканала. Причины, по которым производство сериала решено не продолжать, пока не уточняются. Сериал «Служба новостей» рассказывает о работе сотрудников вымышленного новостного телеканала Atlantis Cable News (ACN). При этом в большинстве эпизодов сериала вымышленный телеканал занимается новостями, произошедшими в реальной жизни. Идея сериала принадлежит Аарону Соркину («Социальная сеть», «Человек, который изменил все»), который также является сценаристом каждого из эпизодов. Первый сезон сериала вышел на канале HBO в июне 2012 года. Второй сезон «Службы новостей» был показан в июле—сентябре 2013 ...</td>\n",
       "      <td>[предстоящий, сезон, телесериал, служба, новость, newsroom, выходить, телеканал, стать, последний, сообщать, reuters, понедельник, январь, объявить, пресс, служба, телеканал, причина, который, производство, сериал, решить, продолжать, пока, уточняться, сериал, служба, новость, рассказывать, работа, сотрудник, вымышленный, новостной, телеканал, atlantis, cable, news, большинство, эпизод, сериал, вымышленный, телеканал, заниматься, новость, произойти, реальный, жизнь, идея, сериал, принадлежать, аарон, соркина, социальный, сеть, человек, который, изменить, весь, который, также, являться, сценарист, каждый, эпизод, сезон, сериал, выйти, канал, июнь, сезон, служба, новость, показать, июль, сентябрь, осень, объявить, план, продлить, сериал, сезон]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Стоимость объектов космодрома Восточный увеличилась примерно на 13 миллиардов рублей из-за применяемой системы сметных нормативов. Об этом в понедельник, 9 февраля, сообщает РИА Новости со ссылкой на пресс-службу Счетной палаты (СП). Согласно данным аудиторской проверки, стоимость строительства выросла на 20 процентов. Как пояснили в пресс-службе СП, применяемая классификация сметных нормативов дала возможность использовать «индивидуальные нормативы для отдельных объектов». Результаты аудита Счетной палаты были отправлены в Федеральную службу безопасности, Генеральную прокуратуру, Федеральную антимонопольную и налоговую службы. Завершение следствия по делу о хищении бюджетных средств при строительстве космодрома «Восточный» передвинули на конец марта. Уголовное дело по части 4 статьи 1...</td>\n",
       "      <td>[стоимость, объект, космодром, восточный, увеличиться, примерно, миллиард, рубль, применять, система, сметный, норматив, понедельник, февраль, сообщать, новость, ссылка, пресс, служба, счётный, палата, согласно, данные, аудиторский, проверка, стоимость, строительство, вырасти, процент, пояснить, пресс, служба, применять, классификация, сметный, норматив, дать, возможность, использовать, индивидуальный, норматив, отдельный, объект, результат, аудит, счётный, палата, отправить, федеральный, служба, безопасность, генеральный, прокуратура, федеральный, антимонопольный, налоговый, служба, завершение, следствие, дело, хищение, бюджетный, средство, строительство, космодром, восточный, передвинуть, конец, март, уголовный, дело, часть, статья, хищение, чужое, имущество, вверить, виновный, групп...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           lemmas\n",
       "120  Клуб НХЛ \"Вашингтон Кэпиталс\" проиграл второй матч серии 1/4 финала Кубка Стэнли. На своей площадке \"Вашингтон\" уступил команде \"Тампа-Бей Лайтнинг\" со счетом 2:3. Таким образом, \"Тампа\" повела в серии до четырех побед со счетом 2:0. Об этом сообщает официальный сайт лиги. В концовке первого периода счет открыл хоккеист \"Тампы\" Венсан Лекавалье. На 35-й минуте отличился игрок \"Вашингтона\" Брук Лайк. В середине третьего периода \"Тампа\" вновь вышла вперед - шайбу забросил Мартен Сен-Луи. За минуту и восемь секунд до конца основного времени Александр Овечкин перевел игру в овертайм, но в дополнительное время \"Тампа\" добилась победы - вновь отличился Лекавалье. В другом матче, состоявшемся в ночь с 1 на 2 мая, \"Сан-Хосе Шаркс\" обыграл \"Детройт Ред Уингс\" со счетом 2:1. \"Сан-Хосе\" ведет в с...  [клуб, вашингтон, кэпиталс, проиграть, матч, серия, финал, кубок, стэнли, свой, площадка, вашингтон, уступить, команда, тампа, бить, лайтнинга, счёт, образ, тампа, повести, серия, четыре, победа, счёт, сообщать, официальный, сайт, лига, концовка, первое, период, счёт, открыть, хоккеист, тамп, венсан, лекавалье, минута, отличиться, игрок, вашингтон, брук, лайк, середина, третье, период, тампа, вновь, выйти, вперёд, шайба, забросить, мартен, минута, восемь, секунда, конец, основный, время, александр, овечкин, перевести, игра, овертайм, дополнительный, время, тампа, добиться, победа, вновь, отличиться, лекавалье, друг, матч, состояться, ночь, хосе, шаркс, обыграть, детройт, уингс, счёт, хосе, вести, серия, счёт, серия, нэшвилл, предаторс, ванкувер, кэнакс, матч, счёт, равный, бостон, брюи...\n",
       "40   Предстоящий третий сезон телесериала «Служба новостей» («Newsroom»), выходящего на телеканале HBO, станет последним. Об этом, сообщает Reuters, в понедельник, 13 января, объявила пресс-служба телеканала. Причины, по которым производство сериала решено не продолжать, пока не уточняются. Сериал «Служба новостей» рассказывает о работе сотрудников вымышленного новостного телеканала Atlantis Cable News (ACN). При этом в большинстве эпизодов сериала вымышленный телеканал занимается новостями, произошедшими в реальной жизни. Идея сериала принадлежит Аарону Соркину («Социальная сеть», «Человек, который изменил все»), который также является сценаристом каждого из эпизодов. Первый сезон сериала вышел на канале HBO в июне 2012 года. Второй сезон «Службы новостей» был показан в июле—сентябре 2013 ...                                                 [предстоящий, сезон, телесериал, служба, новость, newsroom, выходить, телеканал, стать, последний, сообщать, reuters, понедельник, январь, объявить, пресс, служба, телеканал, причина, который, производство, сериал, решить, продолжать, пока, уточняться, сериал, служба, новость, рассказывать, работа, сотрудник, вымышленный, новостной, телеканал, atlantis, cable, news, большинство, эпизод, сериал, вымышленный, телеканал, заниматься, новость, произойти, реальный, жизнь, идея, сериал, принадлежать, аарон, соркина, социальный, сеть, человек, который, изменить, весь, который, также, являться, сценарист, каждый, эпизод, сезон, сериал, выйти, канал, июнь, сезон, служба, новость, показать, июль, сентябрь, осень, объявить, план, продлить, сериал, сезон]\n",
       "20   Стоимость объектов космодрома Восточный увеличилась примерно на 13 миллиардов рублей из-за применяемой системы сметных нормативов. Об этом в понедельник, 9 февраля, сообщает РИА Новости со ссылкой на пресс-службу Счетной палаты (СП). Согласно данным аудиторской проверки, стоимость строительства выросла на 20 процентов. Как пояснили в пресс-службе СП, применяемая классификация сметных нормативов дала возможность использовать «индивидуальные нормативы для отдельных объектов». Результаты аудита Счетной палаты были отправлены в Федеральную службу безопасности, Генеральную прокуратуру, Федеральную антимонопольную и налоговую службы. Завершение следствия по делу о хищении бюджетных средств при строительстве космодрома «Восточный» передвинули на конец марта. Уголовное дело по части 4 статьи 1...  [стоимость, объект, космодром, восточный, увеличиться, примерно, миллиард, рубль, применять, система, сметный, норматив, понедельник, февраль, сообщать, новость, ссылка, пресс, служба, счётный, палата, согласно, данные, аудиторский, проверка, стоимость, строительство, вырасти, процент, пояснить, пресс, служба, применять, классификация, сметный, норматив, дать, возможность, использовать, индивидуальный, норматив, отдельный, объект, результат, аудит, счётный, палата, отправить, федеральный, служба, безопасность, генеральный, прокуратура, федеральный, антимонопольный, налоговый, служба, завершение, следствие, дело, хищение, бюджетный, средство, строительство, космодром, восточный, передвинуть, конец, март, уголовный, дело, часть, статья, хищение, чужое, имущество, вверить, виновный, групп..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.head(200)\n",
    "data['lemmas'] = lemmas\n",
    "data.sample(3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1. Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
